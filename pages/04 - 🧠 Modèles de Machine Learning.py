import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import scipy.stats as stats
from scipy.stats import pearsonr
from scipy.stats import spearmanr
import statsmodels.api

dfent = pd.read_csv("base_etablissement_par_tranche_effectif.csv")
dfgeo = pd.read_csv ("name_geographic_information.csv")
dfsal = pd.read_csv("net_salary_per_town_categories.csv")
#dfpop = pd.read_csv("population.csv",low_memory=False)

df1 = pd.read_csv("df_ratio.csv", index_col="CODGEO")
df2 = pd.read_csv("df_full_cadre_tertiaire.csv", index_col="CODGEO")
df3 = pd.read_csv("df_full_cadre_tertiaire_tag_dep.csv", index_col="CODGEO")
df4 = pd.read_csv("df_cat_poste.csv", index_col="CODGEO")

if 1 == 1 :
    st.title("üí∂ French Industry üí∂")
    
    st.markdown("# üß† Mod√®les de Machine Learning")
    st.sidebar.markdown("# üß† Mod√®les de Machine Learning")

    
    st.subheader("Objectif")
    st.write("Pr√©dire le salaire moyen d'une personne (variable continue) en fonction des donn√©es contenues dans les variables explicatives qui le composent.")
    
    st.write("")
    st.write("")

    if st.button("Mod√®les de r√©gression") :
        st.subheader("Choix des mod√®les")
        st.markdown("""
                    Afin de pr√©dire le salaire moyen, nous avons √©tudi√© la performance de plusieurs mod√®les de machine learning :
                    - R√©gression lin√©aire
                    - Ridge
                    - Lasso
                    - Ridge
                    - Elastic Net
                    - KNN
                    - Decision Tree
                    - Random Forest
                    - SVR.

                    Ces mod√®les ont √©t√© appliqu√©s √† 4 Dataframes issus de pr√©-processing diff√©rent afin de comparer les r√©sultats et de d√©terminer le meilleur mod√®le.
        """)

        st.write("")
        st.write("")

    # Pr√©sentation du jeu de mod√©lisation n¬∞1
        
    if st.button("Choix du jeu de mod√©lisation"):
        st.subheader("Jeu de mod√©lisation n¬∞1")
        st.markdown("""
                    Ce DataFrame a √©t√© cr√©√© √† partir des donn√©es fournies pour le projet et avec les variables (ensemble de ratios sur la population et les entreprises) cr√©√©es lors de l‚Äôinitialisation des matrices de corr√©lation
                    """)
        st.write("")
        st.write("")
        st.dataframe(df1.head())

        st.markdown("#### Tableau global des r√©sultats")
        result1 = pd.read_csv("result_model1.csv", index_col = 1)

        result1.drop(columns=result1.columns[0], axis=1, inplace=True)

        st.dataframe(result1)

        st.markdown("""
                    #### Interpr√©tation


                    On constate des R¬≤ plut√¥t faibles (autour de 0.4, voire 0.2) ou du sur apprentissage lorsque le R¬≤ est meilleur (pour Random Forest et SVR).  
                    
                    
                    La MSE sur l‚Äôensemble de test est assez √©lev√©e. La RMSE de test, √† son minimum est √† 1.42 (donc un √©cart moyen de 1.42‚Ç¨ sur le salaire moyen horaire pr√©dit).  
                    
                    
                    Pour ce premier jeu de mod√©lisation, on peine donc √† trouver un ‚Äúmeilleur‚Äù mod√®le. Nous souhaitons donc am√©liorer notre jeu de donn√©es.  
                    """)
        st.write("")
        st.write("")


    # Pr√©sentation du jeu de mod√©lisation n¬∞2
        
        st.subheader("Jeu de mod√©lisation n¬∞2")
        st.markdown("""
                    Sur la base du DataFrame pr√©c√©dent, nous avons ajout√© :
                    - La proportion de cadre par commune en 2020
                    - La proportion de personnes travaillant dans le tertiaire par commune en 2020

                    """)
        st.write("")
        st.write("")
        st.dataframe(df2.head())

        st.markdown("#### Tableau global des r√©sultats")
        # Insertion du dataframe r√©sultats

        result2 = pd.read_csv("result_model2.csv", index_col = 1)

        result2.drop(columns=result2.columns[0], axis=1, inplace=True)
        st.dataframe(result2)

        st.markdown("""
                    #### Interpr√©tation
                    Les mod√®les KNN et SVR semblent les plus int√©ressants (les √©carts entre R¬≤ train et R¬≤ test sont les plus faibles, tout en √©tant proche de 1). Les √©carts de pr√©dictions (RMSE respectivement √† 1.28 et 1.11).
                    
                    
                    Le Random Forest a une RMSE faible mais l‚Äô√©cart entre les valeurs de R¬≤ t√©moignent d‚Äôun surapprentissage.
                    
                    
                    Afin d'affiner ces r√©sultats, nous effectuons un GridSearch pour √©valuer les meilleurs param√®tres √† passer pour chacun de ces mod√®les.

                    """)
        st.write("")
        st.write("")

        st.markdown("#### R√©sultats apr√®s Gridsearch")
        # Insertion r√©sultat gridsearch
        data = {
        'Model': ['KNN', 'SRV'],
        'R2_train': [0.859765, 0.885198],
        'R2_test': [0.681018, 0.802175],
        'R2_full': [0.815537,0.864396],
        'MAE_train': [0.628312, 0.772503],
        'MAE_test': [0.934093, 1.180191],
        'MSE_train': [0.912875, 0.476711],
        'MSE_test': [2.114212, 0.663887],
        'RMSE_train': [0.955445, 0.878921],
        'RMSE_test': [1.454033, 1.086366]
                }
        
        tab = pd.DataFrame(data)
        tab.set_index('Model', inplace = True)
        st.dataframe(tab)

        st.markdown("""
                    Le mod√®le KNN a un surapprentissage beaucoup trop important. Le mod√®le SVR a une meilleure erreur quadratique, sans pour autant perdre la qualit√© de son √©cart entre r2 train et test.

                    
                    On constate en observant l‚Äôimportance des variables explicatives dans les diff√©rents mod√®les que la proportion de cadres est d√©sormais la variable la plus importante.

                    
                    Est-il possible d‚Äôam√©liorer nos scores avec l‚Äôajout d‚Äôune donn√©e sur le d√©partement d‚Äôappartenance (comme pour l‚Äôappartenance √† la r√©gion Ile-de-France) ?


                    """)
        st.write("")
        st.write("")


    # Pr√©sentation du jeu de mod√©lisation n¬∞3

        st.subheader("Jeu de mod√©lisation n¬∞3")
        st.markdown("""
                    Sur base du DataFrame pr√©c√©dent, nous avons ajout√© une colonne par d√©partement encod√© selon si la commune fait partie (1) ou non (0) √† ce d√©partement (OneHotEncoder).
                            
                            """)

        st.write("")
        st.write("")
        st.dataframe(df3.head())

        st.markdown("#### Tableau global des r√©sultats")
        # Insertion du dataframe r√©sultats
        result3 = pd.read_csv("result_model3.csv", index_col = 1)

        result3.drop(columns=result3.columns[0], axis=1, inplace=True)

        st.dataframe(result3)

        st.markdown("""
                    #### Interpr√©tation
                    Les r√©sultats ne sont pas sensiblement meilleurs. Le SVR est un plus grand surapprentissage que le jeu de donn√©es pr√©c√©dent, sans pour autant am√©liorer l‚Äôerreur quadratique.
                    """)
        st.write("")
        st.write("")


    # Pr√©sentation du jeu de mod√©lisation n¬∞4
        
        st.subheader("Jeu de mod√©lisation n¬∞4")
        st.markdown("""
                    Ce 4e DataFrame a √©t√© cr√©√© depuis le fichier net_salary.csv fourni pour le projet. Les colonnes ont √©t√© pivot√© afin de cat√©goriser le salaire moyen selon le genre et la cat√©gorie de poste :
                    - genre = 1 : femme / 2 : homme
                    - cat_poste = 1 : travailleur(euse) / 2 : employ√©(e) / 3 : cadre moyen / 4 : cadre

                    """)
        st.write("")
        st.write("")
        st.dataframe(df4.head())

        st.markdown("#### Tableau global des r√©sultats")
        # Insertion du dataframe r√©sultats
        # result3 = pd.read_csv("result_model4.csv", index_col = 1)

        # result3.drop(columns=result3.columns[0], axis=1, inplace=True)

        # st.dataframe(result4)

        st.markdown("""
                    #### Interpr√©tation
                    On note un R¬≤ de test sup√©rieur au R¬≤ train sur le mod√®le SVR. Cependant, les valeurs des RMSE de test sont moins int√©ressantes que sur le DataFrame n¬∞2.

                    
                    Il est int√©ressant de noter que pour SVR, nous avons un DataFrame de grandeur optimale d‚Äôapr√®s la courbe d‚Äôapprentissage. 

                    
                    Le mod√®le SVR offre les meilleurs r√©sultats. Si on analyse de plus pr√®s le graphique de dispersions des r√©sidus de ce mod√®le, on constate de nombreux r√©sidus avec une valeur parfois sup√©rieure √† 5, ce qui est tr√®s important pour un salaire horaire.

                    """)
        st.write("")
        st.write("")
    
        st.subheader("Mod√®le le plus performant")

        st.markdown("""
                    En conclusion, le jeu de donn√©es avec la proportion de cadre semble offrir le meilleur compromis en termes de performance (jeu de mod√©lisation n¬∞2 avec le mod√®le SVR).

                     
                    Les mod√®les Random Forest obtiennent de bons r√©sultats d‚Äôerreur quadratique, malheureusement, l‚Äô√©cart des R¬≤ est trop important signe de surapprentissage.

                    """)
        st.write("")
        st.write("")

    if st.button("Evaluation graphique du mod√®le") :
        
        #Courbe d'apprentissage
        st.subheader("Courbe d'apprentissage du mod√®le")
        # ins√©rer la courbe d'apprentissage

        image_apprentissage = "https://zupimages.net/up/24/11/m3js.png"

        st.image(image_apprentissage, use_column_width=True)

        st.markdown("""
                    ##### Points √† retenir :         
                    - Mod√®le qui s'ajuste au fur √† mesure aux donn√©es d'entrainement.
                    - Pas de soup√ßon d'overfitting
                    """)
        
        st.write("")
        st.write("")

        #QQplot, residu et prediction vs vraies
        st.subheader("Graphique des r√©sidus et QQ-plot")
        # ins√©rer qqplot et r√©sidu
        image_qqplot = "https://zupimages.net/up/24/11/n6me.png"

        st.image(image_qqplot, use_column_width=True)

        st.write("")
        st.write("")

        st.markdown("""
                    ##### Points √† retenir :      
                    - Distribution relativement centr√©e autour de 0 et entre -2.5 et 2.5
                    - Quelques valeurs extr√™mes.

                    """)
        
        st.write("")
        st.write("")


    if st.button("Features importance") :
        
        st.markdown("""
                    Le SRV n'ayant pas de Features importance, nous allons pr√©senter ceux du RandomForestRegressor, un mod√®le qui donne aussi des r√©sultats tr√®s satisfaisant.
                    """
                    )

        # Visualiser les importances des caract√©ristiques
        st.subheader("Importance des variables du RandomForestRegressor")
        
        # ins√©rer le graphe
        image_importances = "https://zupimages.net/up/24/11/82nd.png"

        st.image(image_importances, use_column_width=True)
        st.markdown("""
                    On remarque que la variable la plus importante est le ratio_cadre qui repr√©sente 70% pour le mod√®le.
                    """)
